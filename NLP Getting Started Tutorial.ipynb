{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NLP Getting Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import feature_extraction, linear_model,model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"data/nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인하기\n",
    "target 0 : 재난이 아닌 트위터  \n",
    "target 1 : 재난인 트위터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재난이 아닌 트위터 중 첫번째 트위터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's up man?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['target'] == 0]['text'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재난인 트위터 중 첫번째 트위터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 생성\n",
    "모델을 생성하기 위한 가설을 간단하다. 각각의 트윗이 가지고 있는 단어들이 해당 트윗이 재난인지 아닌지를 구분하는데 좋은 지표가 될것이라는 가설이다.  \n",
    "\n",
    "`sklearn`의 `CountVectorizer`을 사용할 것임. 모델에 입력할 수 있도록 각각의 트위터에 있는 단어들의 출현빈도(Count)로 문장을 벡터화하는 메서드이다. (전체 단어들에 대한 벡터를 만들고 각각의 문장이 해당 단어를 가지고 있는지 확인하여 count 하여 벡터로 반환해줌- 아래 예시를 보면서 확인)  \n",
    "\n",
    "📌여기서 말하는 벡터는 머신러닝 모델에 입력할 수 있는 숫자들의 집합을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**예시로 첫 5개의 트위터만 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.todense()` 메소드를 사용하여(현재 벡터가 sparse이기 때문에) sparse matrix 를 변환해줌. \n",
    "\n",
    "[.todense()메소드 참고](https://rfriend.tistory.com/tag/todense%28%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x54 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과는 다음을 의미함.\n",
    "1. 첫 5개의 트윗에는 54개의 중복되지 않은 유일한 단어들이 존재함.\n",
    "2. 첫번째 트위터에는 이러한 유일한 토큰이 일부분 존재함, 0이 아닌 숫자들은 첫번째 트윗에 존재하는 토큰을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data에는 `fit_transform` 을 사용하고, test_data에는 `transform` 을 사용함. 결론적으로 말하면 train_data 에만 `fit_transform` 를 사용함. `fit_transform` 은 정규화를 해주는 메소드인데 fit 은 평균 𝜇과  표준편차 𝜎 를 계산해주고 transform 은 정규화를 적용해주는 역할을 함. \n",
    "\n",
    "그래서  train_data 에서 계산된 평균과 표준편차를 적용하기 위해 test_data 에 transfom 메소드를 통해 적용해줌(`fit_transform` 에서 계산된 값이 저장되어 있음)  \n",
    "\n",
    "[fit_transform, transform에 대해서](https://deepinsight.tistory.com/165)\n",
    "[SKLEARN에서 FIT_TRANSFORM()과 TRANSFORM()의 차이](https://nurilee.com/2020/01/06/sklearn%EC%97%90%EC%84%9C-fit_transform%EA%B3%BC-transform%EC%9D%98-%EC%B0%A8%EC%9D%B4/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "위에서 언급했듯이, 각각의 트윗에 포함된 단어가 해당 트윗이 재난인지 아닌지 판단하는데 중요한 지표가 될 것이라고 가정했기 때문에, 트윗의 특정 단어의 존재가 그 트윗이 진짜인지 아닌지 판단하는데 직접적인 연결고리가 될 것임.\n",
    "\n",
    "여기서 가정하는 것은 선형관계이기 때문에 선형 모델을 적용하기로 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 벡터가 매우 크기 때문에 다른 단어를 제외하지 않으면서 모델의 가중치를 0으로 향하도록 해야함. 이러한 방법을 사용하기에 ridge regression 이 좋은 방법이 될 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 테스트해고 훈련데이터에 얼마나 잘 작동하는지 파악해 봄. 이를 위해 `cross-validation` 을 사용할 예정임. (일정 부분의 데이터를 훈련에 사용하고, 나머지 데이터를 검증에 사용하는 방식)  \n",
    "\n",
    "만약 이것을 여러번 시행한다면(다른 비율을 사용하여) 특정 모델이나 방법이 어떻게 수행이 되는지에 대한 좋은 아이디어를 얻을 수 있음.  \n",
    "\n",
    "본 대회의 평가 방법은 F1 score 이기 때문에 이를 사용할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59421842, 0.5642787 , 0.64149093])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 스코어를 보게 되면 매우 좋지 않은 것을 확인해볼 수 있음. 해당 예측은 대략적으로 리더보드 점수에 0.64 정도를 기록할 것으로 보여짐.   \n",
    "이를 향상시키기 위해 많은 방법들을 시도해보자(TFIDF, LSA, LSTM / RNNs...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/nlp-getting-started/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"data/nlp-getting-started/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
