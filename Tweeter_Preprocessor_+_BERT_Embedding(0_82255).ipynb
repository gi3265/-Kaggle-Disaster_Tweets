{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-portfolio",
   "metadata": {},
   "source": [
    "Runned by COLAB & Adjusted the ipynb to be able to runned by jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-advertising",
   "metadata": {
    "id": "optical-sheriff"
   },
   "source": [
    "Reference: https://www.youtube.com/watch?v=_eSGWNqKeeY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-formation",
   "metadata": {
    "id": "i_6fnyMYG8ug"
   },
   "source": [
    "# SETUP(When Using COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "desirable-joining",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfZXGwy5G8Yy",
    "outputId": "7001c4f7-244a-480d-ac6c-449cc8b17f74"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed575d876f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU Device name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-mileage",
   "metadata": {
    "id": "LeW3iQLWICW1"
   },
   "source": [
    "torch가 GPU를 사용하도록 하려면, GPU를 확인하고 device로 직접 지정해야 한다 나중에 training loop를 돌 때 데이터들(Tensors)을 해당 GPU에 로드할 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-costa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVng4epSH2uc",
    "outputId": "69e794d4-1925-4387-b49a-6b9738562f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using the CPU instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SGI\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 활용 가능한 GPU가 있다면\n",
    "if torch.cuda.is_available():\n",
    "    # 파이토치에게 GPU를 이용하도록 명령\n",
    "    device = torch.device('cuda')\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU: ', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available. Using the CPU instead')\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-blackberry",
   "metadata": {
    "id": "uhPA3ILyYmVQ"
   },
   "source": [
    "# 라이브러리 import 및 데이터 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approved-doctrine",
   "metadata": {
    "id": "signal-lemon"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legislative-horse",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quick-interpretation",
    "outputId": "4ab34daf-f7e0-4897-d05f-990d88275ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n"
     ]
    }
   ],
   "source": [
    "path = \"data\"\n",
    "train_df = pd.read_csv(path + \"/train.csv\")\n",
    "test_df = pd.read_csv(path + \"/test.csv\")\n",
    "sample_submission = pd.read_csv(path + '/sample_submission.csv')\n",
    "\n",
    "print(' Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-philosophy",
   "metadata": {
    "id": "empty-filing"
   },
   "source": [
    "# Train 데이터셋 전처리(1)- 누락값 제거 및 깔끔한 Corpus만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legal-peace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "sealed-standard",
    "outputId": "2897857e-a218-4d9e-fe0c-5b55f02ba347"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first five rows of the table.\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accompanied-tomato",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuxA-VN23Dqj",
    "outputId": "533f65ca-0f31-48fd-d670-c804b43e8eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 -> tweet-preprocessor 이용\n",
    "# !pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-birmingham",
   "metadata": {
    "id": "59AO9ph53I04"
   },
   "source": [
    "*   tweet-preprocessor\n",
    "\n",
    "  *   URLs\n",
    "  *   Mentions\n",
    "  *   Reserved words (RT, FAV)\n",
    "      *  RT: Retweet의 약자\n",
    "      *  FAV:  Favorite의 약자\n",
    "  *   Emojis\n",
    "  *   Smileys\n",
    "  *   JSON and .txt file support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structured-audit",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7v_LqQwM3IOJ",
    "outputId": "eee6de86-b3bb-4f78-d6cd-04185c92c4fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SGI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SGI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor \n",
    "from wordcloud import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "streaming-royalty",
   "metadata": {
    "id": "v5G_uOSi4P9L"
   },
   "outputs": [],
   "source": [
    "stop = set(STOPWORDS).union(set(['FAV' , 'RT']))  ## .union() =  합집합\n",
    "lemma = WordNetLemmatizer()  ## NLTK에서는 표제어(단어의 뿌리) 추출을 위한 도구인 WordNetLemmatizer를 지원\n",
    "preprocessor.set_options(preprocessor.OPT.URL, preprocessor.OPT.MENTION, preprocessor.OPT.NUMBER, preprocessor.OPT.RESERVED)  ## OPT = option(https://pypi.org/project/tweet-preprocessor/)\n",
    "\n",
    "def clean(text):   \n",
    "    text = preprocessor.clean(text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    stop_free = \" \".join([i for i in text.split(' ') if (i not in stop)])\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numeric-pioneer",
   "metadata": {
    "id": "XJmyk0aS4kM2"
   },
   "outputs": [],
   "source": [
    "# 정제된 데이터\n",
    "train_df.text = train_df.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immediate-congress",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_x1Y-y34mOB",
    "outputId": "43b0b90a-3327-4355-b876-d96e245789ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Our Deeds Reason earthquake May ALLAH Forgive u\n",
       "1                   Forest fire near La Ronge Sask Canada\n",
       "2       All resident asked shelter place notified offi...\n",
       "3       people receive wildfire evacuation order Calif...\n",
       "4       Just got sent photo Ruby Alaska smoke wildfire...\n",
       "                              ...                        \n",
       "7608    Two giant crane holding bridge collapse nearby...\n",
       "7609    The control wild fire California even Northern...\n",
       "7610                    M194 0104 UTC5km S Volcano Hawaii\n",
       "7611    Police investigating ebike collided car Little...\n",
       "7612    The Latest More Homes Razed Northern Californi...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_df.text\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-chain",
   "metadata": {
    "id": "monetary-venue"
   },
   "source": [
    "### 간단한 EDA:단어별 재난 연관률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handy-pressure",
   "metadata": {
    "id": "promising-raising"
   },
   "outputs": [],
   "source": [
    "keywords_targets = train_df.groupby('keyword')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "apart-provision",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vocal-cowboy",
    "outputId": "979edca3-d6b3-4ac0-d3f1-8880757ce795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "ablaze                 0.361111\n",
       "accident               0.685714\n",
       "aftershock             0.000000\n",
       "airplane%20accident    0.857143\n",
       "ambulance              0.526316\n",
       "                         ...   \n",
       "wounded                0.702703\n",
       "wounds                 0.303030\n",
       "wreck                  0.189189\n",
       "wreckage               1.000000\n",
       "wrecked                0.076923\n",
       "Name: target, Length: 221, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heavy-nicholas",
   "metadata": {
    "id": "golden-trout"
   },
   "outputs": [],
   "source": [
    "k_t_corelation = pd.DataFrame(keywords_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "verbal-intensity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "fitting-welsh",
    "outputId": "1fd59435-09c9-4f2e-a7d1-97f1c6314509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>debris</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil%20spill</th>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target\n",
       "keyword              \n",
       "debris       1.000000\n",
       "wreckage     1.000000\n",
       "derailment   1.000000\n",
       "outbreak     0.975000\n",
       "oil%20spill  0.973684"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_t_corelation = k_t_corelation.sort_values(by='target', ascending=False)\n",
    "k_t_corelation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bottom-short",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "approximate-mouse",
    "outputId": "e08b9397-0324-4bf2-fe13-295b3b794ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-clearing",
   "metadata": {
    "id": "former-stanley"
   },
   "source": [
    "해당 단어 등장 대비 실제 재해 트윗인 비율을 기준으로 221개의 keyword 중, 상위 5개 단어를 뽑아봄: 특히 debris, wreckage, derailment 이 3개 단어는 등장했을 경우 모두 재난 상황을 지칭한 경우였음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-english",
   "metadata": {
    "id": "liked-chinese"
   },
   "source": [
    "#### 재난 상황 트윗 임의로 10개 뽑아 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "approved-rebecca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriented-stadium",
    "outputId": "fa02ec17-a5b1-45ab-8724-5894e763e1d0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See Aug PoconoRecord How Many Households Have Emergency Plan\n",
      "\n",
      "\n",
      "Usama bin Ladins family dead airplane crash Naturally accident\n",
      "\n",
      "\n",
      "South Sac I5 S I5 S rd Ave Ofr Trfc CollisionNo Inj\n",
      "\n",
      "\n",
      "Firefighters Connecticut headed California fight wild fire\n",
      "\n",
      "\n",
      "Seven Chinese Christians Are Detained Amid Widespread Anger Over Cross\n",
      "Demolition\n",
      "\n",
      "\n",
      "patrickjbutler Excellent damiengayle eyewitness account Kids Company closure You\n",
      "drop bomb expectÛ_\n",
      "\n",
      "\n",
      "Someone teaching obedience will obliterate trial life trying sell used car\n",
      "Jesuss life blow theory\n",
      "\n",
      "\n",
      "I totally agree They rape kill destroy leave land desolate Action need happen\n",
      "swarm swell\n",
      "\n",
      "\n",
      "ok peace I hope I fall cliff along dignity\n",
      "\n",
      "\n",
      "Theres fire Catalinas Looks kinda cool This picture doesnt justice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import random\n",
    "\n",
    "# Wrap text to 80 characters\n",
    "wrapper = textwrap.TextWrapper(width = 80)\n",
    "\n",
    "# filter to just the 'Disaster' comments\n",
    "disaster_examples = train_df.query('target == 1')['text']\n",
    "\n",
    "# Randomly choose some examples\n",
    "for i in range(10):\n",
    "    j = random.choice(disaster_examples.index)\n",
    "    print('')\n",
    "    print(wrapper.fill(disaster_examples[j]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "human-contamination",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "engaging-geography",
    "outputId": "9424d859-29c4-4a2a-8104-c04983d44e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,613개의 트윗 중 3,271개는 재난 관련 트윗임(42.97%).\n"
     ]
    }
   ],
   "source": [
    "# What percentage of the comments are disaster tweets?\n",
    "total_tweets = len(train_df)\n",
    "num_disasters = len(train_df.query('target == 1'))\n",
    "\n",
    "print('{:,}개의 트윗 중 {:,}개는 재난 관련 트윗임({:.2%}).'.format(total_tweets, num_disasters, num_disasters/total_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-candle",
   "metadata": {
    "id": "accessible-eugene"
   },
   "source": [
    "keyword == NaN인 행들을 날린 train_df는 재난 트윗과 재난이 아닌 트윗이 꽤 균형 있게 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-palestine",
   "metadata": {
    "id": "lonely-might"
   },
   "source": [
    "다양한 python format 형식들: https://www.w3schools.com/python/ref_string_format.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "directed-rental",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "surface-garbage",
    "outputId": "a1affcb1-a7d8-4464-995a-92cd219066b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 tweets 중 최대 길이: 138, 최소 길이 3 \n",
      "재해 tweets 중 최대 길이: 8, 최소 길이 2\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 train_df의 text들 중 가장 긴 tweet의 단어 개수와 가장 짧은 단어 개수 출력\n",
    "total_mx = max([len(length) for length in train_df.text])\n",
    "total_mn = min([len(length) for length in train_df.text])\n",
    "disaster_mx = max([len(length) for length in train_df.query('target == 1')])\n",
    "disaster_mn = min([len(length) for length in train_df.query('target == 1')])\n",
    "\n",
    "print('전체 tweets 중 최대 길이: {:>,}, 최소 길이 {:>,} \\n재해 tweets 중 최대 길이: {}, 최소 길이 {}'.format(total_mx, total_mn, disaster_mx, disaster_mn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-soccer",
   "metadata": {
    "id": "ClVSPp_eQrwL"
   },
   "source": [
    "# Train 데이터셋 전처리(2)- Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-exhaust",
   "metadata": {
    "id": "burning-utilization"
   },
   "source": [
    "## BERT Input Length Limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "single-screen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ou_lL7926DqI",
    "outputId": "0f5ed50a-432b-4e59-ab96-7b52a90f0a99",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sgi\\anaconda3\\lib\\site-packages (4.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (4.56.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: requests in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\sgi\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "failing-arrest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182,
     "referenced_widgets": [
      "92fc8899b6e04a4886e66b3c3dca388e",
      "c78eb26897e147f38797dbe2ccd7e4ad",
      "e7709c0d0b0f4a2298b5fdd0e0f95d50",
      "ca380b0061e047e1800628a47a547b5d",
      "317f590da93c4773bfc567e1476c9d3d",
      "471c0056a7f842b8aa5d5d1f8117f9ec",
      "4c7d18eab7b24bf4a237779ead1ec4d4",
      "2064c5090f21400d836940d4c5c90c56",
      "c476ab52d9cb48b8856a820dd368cdb1",
      "4a4e95bae7a34e63b218c2687a99aff8",
      "f29ae599f89f4c07bcaaad154b76069b",
      "d892483b862c45f48c906f2393f1a40f",
      "bd4b90bbf5ed425ca531bdf85a784940",
      "79f68bacefd94c20ba9c65b22f0c0892",
      "6938e752c86c4c9fb22fda671242646e",
      "ffbedc1ccaeb43f883189743d0a422c6",
      "880610c74dc549d88957867b7469ac6e",
      "3b54731995ac496e9f92577a6fb822ba",
      "962245dce77c4cb1ae89f8bd5ccf9830",
      "48a503528cc24d0e8db6bd6056e80d6c",
      "8fcd3ce79f1d45f5a6d31ca8f3515a5d",
      "ee13ce48e1964af588039f4dfae9a621",
      "4c33de7bd446464c9b3e3de8954e3d1c",
      "b45509a3910044999219a2da6b0fd5d3"
     ]
    },
    "id": "moderate-subject",
    "outputId": "1a1d3b96-0b5b-4933-919f-f4549802a46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Bert_Tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "print(\"Load Bert_Tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-precipitation",
   "metadata": {
    "id": "reflected-interaction"
   },
   "source": [
    "BertTokenizer이 어떻게 작동되는지 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "incorporated-cyprus",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prescribed-buffer",
    "outputId": "a7f60623-eae6-4674-a005-87b37550f6e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df의 첫 번째 text에는 8개의 WordPiece Tokens를 가지고 있다\n",
      "\n",
      "Original Text:\n",
      "\n",
      "Our Deeds Reason earthquake May ALLAH Forgive u\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# 첫 번째 텍스트 꺼내오기\n",
    "sample_text = train_df.iloc[0].text\n",
    "\n",
    "# Run the tokenizer to count up the number of tokens. The tokenizer will split the text into words, punctuations and subwords as needed\n",
    "tokens = tokenizer.tokenize(sample_text)\n",
    "\n",
    "print('train_df의 첫 번째 text에는 {:,}개의 WordPiece Tokens를 가지고 있다'.format(len(tokens)))\n",
    "print('\\nOriginal Text:\\n')\n",
    "print(wrapper.fill(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "spare-verse",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "primary-tyler",
    "outputId": "d484e08e-4a82-4d29-a364-3da87fa93478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Tokens ====\n",
      "\n",
      "our deeds reason earthquake may allah forgive u\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토큰 리스트 출력\n",
    "print('==== Tokens ====\\n')\n",
    "print(wrapper.fill(str(' '.join(tokens))))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-friendship",
   "metadata": {
    "id": "unknown-hotel"
   },
   "source": [
    "## 모든 트윗들 Bert 이용하여 Tokenize(Vectorization 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "gothic-assurance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dimensional-implement",
    "outputId": "1ab33b49-940e-4471-8e13-e48dee222e33",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Tweets...\n",
      " Read 0 tweets.\n",
      " Read 200 tweets.\n",
      " Read 400 tweets.\n",
      " Read 600 tweets.\n",
      " Read 800 tweets.\n",
      " Read 1,000 tweets.\n",
      " Read 1,200 tweets.\n",
      " Read 1,400 tweets.\n",
      " Read 1,600 tweets.\n",
      " Read 1,800 tweets.\n",
      " Read 2,000 tweets.\n",
      " Read 2,200 tweets.\n",
      " Read 2,400 tweets.\n",
      " Read 2,600 tweets.\n",
      " Read 2,800 tweets.\n",
      " Read 3,000 tweets.\n",
      " Read 3,200 tweets.\n",
      " Read 3,400 tweets.\n",
      " Read 3,600 tweets.\n",
      " Read 3,800 tweets.\n",
      " Read 4,000 tweets.\n",
      " Read 4,200 tweets.\n",
      " Read 4,400 tweets.\n",
      " Read 4,600 tweets.\n",
      " Read 4,800 tweets.\n",
      " Read 5,000 tweets.\n",
      " Read 5,200 tweets.\n",
      " Read 5,400 tweets.\n",
      " Read 5,600 tweets.\n",
      " Read 5,800 tweets.\n",
      " Read 6,000 tweets.\n",
      " Read 6,200 tweets.\n",
      " Read 6,400 tweets.\n",
      " Read 6,600 tweets.\n",
      " Read 6,800 tweets.\n",
      " Read 7,000 tweets.\n",
      " Read 7,200 tweets.\n",
      " Read 7,400 tweets.\n",
      " Read 7,600 tweets.\n",
      "DONE.\n",
      "      7613 tweets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 모든 문장 토크나이징 하고 id에 따라 분류하기\n",
    "input_ids  = []\n",
    "\n",
    "# 각 트윗의 토큰 개수 기록\n",
    "token_len = []\n",
    "\n",
    "print('Tokenizing Tweets...')\n",
    "\n",
    "# 각 트윗 마다...\n",
    "for tweet in train_df.text:\n",
    "    # 진행 상황\n",
    "    if ((len(input_ids) % 200) == 0):\n",
    "        print(' Read {:,} tweets.'.format(len(input_ids)))\n",
    "    \n",
    "    # encode will\n",
    "    # 1)트윗을 토크나이징하고, \n",
    "    # 2)[CLS]토큰을 시작 부분에, [SEP]토큰을 마지막 부분에 추가하고, \n",
    "    # 3)토큰을 해당 id에 매칭\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        tweet, # Tweet to encode\n",
    "        add_special_tokens = True,  # add_special_tokens: [CLS]와 [SEP]추가'\n",
    "        # max_length = 512,  # Truncate all tweets\n",
    "        # return_tensors = 'pt'  # Return pytorch tensors.\n",
    "    ) \n",
    "    \n",
    "    # encoded된 트윗을 리스트에 넣기\n",
    "    input_ids.append(encoded_sent)\n",
    "    \n",
    "    # 각 트윗의 토큰 개수 기록\n",
    "    token_len.append(len(encoded_sent))\n",
    "\n",
    "print('DONE.')\n",
    "print('{:>10} tweets'.format(len(input_ids)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-regular",
   "metadata": {
    "id": "distant-scottish"
   },
   "source": [
    "train_df에서 labels 추출한 뒤, 재난 관련 트윗과 재난 관련되지 않은 트윗의 분포 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hawaiian-invention",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coated-suite",
    "outputId": "12cf1790-adca-4cb3-e5f7-bc315cb8b4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3,271 positive (is disaster tweet)\n",
      "  4,342 negative (not disaster tweet)\n"
     ]
    }
   ],
   "source": [
    "labels = train_df.target.to_numpy().astype(int)\n",
    "\n",
    "print('{:>7,} positive (is disaster tweet)'.format(np.sum(labels)))\n",
    "print('{:>7,} negative (not disaster tweet)'.format(len(labels) - np.sum(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-price",
   "metadata": {
    "id": "lesser-polymer"
   },
   "source": [
    "### 토큰 길이 분포에 따른 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "collectible-disco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "individual-mercury",
    "outputId": "94dd899b-33b9-4409-eb55-796c8db0d344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 tweets 중 토큰 최대 개수: 47, 최소 개수: 3, 중간값: 14\n"
     ]
    }
   ],
   "source": [
    "# 토큰나이징 된 train_df의 tweet들 중 가장 긴 tweet의 단어 개수와 가장 짧은 단어 개수 출력\n",
    "\n",
    "print('전체 tweets 중 토큰 최대 개수: {:>,}, 최소 개수: {:>,}, 중간값: {:.0f}'.format(max(token_len), min(token_len), np.median(token_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daily-broadcast",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "academic-blade",
    "outputId": "14040ebe-aae8-476c-9421-6a7a3c17a095"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "sns.set(style = 'darkgrid')\n",
    "\n",
    "# 플롯 크기랑 폰트 사이즈 키우기\n",
    "sns.set(font_scale = 1.5)\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "# 트윗 토큰 개수에 따른 시각화\n",
    "sns.histplot(token_len, kde = False)\n",
    "plt.title(\"Number of Tokens\")\n",
    "plt.xlabel('# of tokens')\n",
    "plt.ylabel('# of tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-penetration",
   "metadata": {
    "id": "burning-error"
   },
   "source": [
    "트윗의 길이와 재난 관련 트윗일 확률 간에 상관 관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "restricted-choice",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "instrumental-archives",
    "outputId": "27704375-9471-4c66-c2c3-b1100d89498d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among tweets that have over 30 tokens, 598(13.9%) are disaster tweets.\n",
      "Among overall tweets, 3,917(51.5%) are 'Disaster Tweets'.\n"
     ]
    }
   ],
   "source": [
    "num_pos = 0\n",
    "num_neg = 0\n",
    "num_pos_residual = 0\n",
    "num_neg_residual = 0\n",
    "\n",
    "for i, l in enumerate(token_len):\n",
    "    # 트윗의 개수가 30이상이라면(그래프 보고 대충 30~정도 토큰이면 긴 트윗에 속한다고 판단)\n",
    "    if l >= 14: #중간값 기준\n",
    "        # 해당 긴 트윗이 재난 관련 트윗인지 아닌지 판단하여 개수 세기\n",
    "        if labels[l] == 1:\n",
    "            num_pos += 1\n",
    "        else:\n",
    "            num_neg += 1\n",
    "    else:\n",
    "        if labels[l] == 1:\n",
    "            num_pos_residual += 1\n",
    "        else:\n",
    "            num_neg_residual += 1\n",
    "            \n",
    "            \n",
    "# 결과 보고\n",
    "print(\"Among tweets that have over 30 tokens, {:,}({:.1%}) are disaster tweets.\".format(num_pos, num_pos/(num_pos+num_neg)))\n",
    "print(\"Among overall tweets, {:,}({:.1%}) are 'Disaster Tweets'.\".format(num_pos+num_pos_residual, (num_pos+num_pos_residual)/len(token_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-cleveland",
   "metadata": {
    "id": "large-skating"
   },
   "source": [
    "트윗의 길이와 재난 트윗일 가능성은 역의 상관관계를 가지고 있다.(재난 상황이 일반적으로 긴박하기에 짧은 트윗으로 빠르게 정보를 공유하고자 하는 경향이 있어서 그런가?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-approach",
   "metadata": {
    "id": "minute-greek"
   },
   "source": [
    "## 트윗들 Padding하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "announced-occasion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "proof-consent",
    "outputId": "d12a99b1-0916-4e52-b629-cff8d0424b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding all tweets to 47 values...\n",
      "\n",
      "Padding Token: \"[PAD]\", ID: 0\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "### 트윗들 padding하기\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 47 #트윗당 최대 토큰 개수로 맞춰서 누락되는 토큰 아예 없애기\n",
    "\n",
    "print('\\nPadding all tweets to %d values...' % MAX_LEN)\n",
    "print('\\nPadding Token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# input_ids에 담긴 트윗당 토큰들을 0으로 채워넣어 Max_len 크기로 패딩하기\n",
    "input_ids = pad_sequences(input_ids, maxlen = MAX_LEN, dtype = 'long', value = 0, truncating = 'post', padding = 'post')\n",
    "print('\\nDONE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-gallery",
   "metadata": {
    "id": "creative-merit"
   },
   "source": [
    "## Attention_Masks 만들기\n",
    "Attention_mast의 역할: 실제 의미가 있는 토큰들만 따로 저장: 이후 tensor로 변환된 뒤 DataLoader에 담겨 BERT 훈련 모델에 입력값으로 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "exposed-wheat",
   "metadata": {
    "id": "material-impossible"
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "# 각 트윗마다...\n",
    "for sent in input_ids:\n",
    "    # Attention Mask 만들기\n",
    "    #  - token_id가 0이라면, 패딩이다. 마스크값에 0을 주고,\n",
    "    #  - token_id가 >0이라면, 의미 있는 토큰이므로 마스크값에 1 주기!\n",
    "    att_mask = [int(token_id>0) for token_id in sent]\n",
    "\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-gallery",
   "metadata": {
    "id": "developmental-measure"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-break",
   "metadata": {
    "id": "metallic-freedom"
   },
   "source": [
    "## 학습용 데이터 90%와 검증용 데이터 10%로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "funky-mailman",
   "metadata": {
    "id": "failing-reaction"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 90% 검증 10%로 나누기\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state = 2018, test_size = 0.1)\n",
    "\n",
    "# 마스크도 나누어 주기\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state = 2018, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-plaintiff",
   "metadata": {
    "id": "timely-processor"
   },
   "source": [
    "BERT 모델은 넘파이보다 파이토치 텐서를 입력값으로 받으므로 파이토치로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reported-catering",
   "metadata": {
    "id": "rational-registration"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-nepal",
   "metadata": {
    "id": "olympic-vermont"
   },
   "source": [
    "## DataLoader 만들기\n",
    "DataLoader class로 iterator만들다. For loop으로 iterate할 때와는 달리, 전체 데이터셋이 메모리에 로드될 필요가 없기에 이렇게 입력값을 먹이는게 메모리 절약에 효과적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "opening-burner",
   "metadata": {
    "id": "applicable-simulation"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# DataLoader는 훈련을 위해 배치 사이즈를 알아야 한다.\n",
    "# 특정 과제를 위해 BERT를 fine-tuning할 때 배치 사이즈 16 혹은 32가 권장된다. \n",
    "batch_size = 32\n",
    "\n",
    "# training_set을 위한 Data_loader 만들기\n",
    "train_data= TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "# validation_set을 위한 Data_Loader 만들기\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-notification",
   "metadata": {
    "id": "damaged-canvas"
   },
   "source": [
    "# Bert Fine-Tuning(Model Training)\n",
    ": 사전 훈련된 BERT모델이 현재의 분류 과제를 잘 수행할 수 있도록 현재 input_data로 훈련시키는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-violation",
   "metadata": {
    "id": "noticed-yukon"
   },
   "source": [
    "## 분류 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-traveler",
   "metadata": {
    "id": "latest-comfort"
   },
   "source": [
    "이제 우리의 input_data들이 알맞은 형태로 정리되었으니 BERT모델을 Fine-Tuning할 차례이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-synthetic",
   "metadata": {
    "id": "assisted-salon"
   },
   "source": [
    "### BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-compound",
   "metadata": {
    "id": "adverse-biography"
   },
   "source": [
    "pretrained 된 BERT 모델을 우리가 원하는 분류 결과를 내놓도록 하기 위해 수정한다. 그런 다음 BERT 모델을 기존에 준비한 Input_Data로 훈련시켜 모델 전체가 우리의 과제에 맞도록 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-market",
   "metadata": {
    "id": "wrapped-berry"
   },
   "source": [
    "### BERT모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "handmade-grain",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ebab2506f5334b6ab1e8e09f7a44c12c",
      "ba52d4f7697f4b9e9c56b62452efb4d1",
      "55dae3e35324482f806dbc48449a0ac0",
      "a2b1452d157449baa090ff17b73be65c",
      "f6c797ae4913458e9f99999b12ece9f3",
      "898a5b5a7b4a4d1a8cf317d1317cda2a",
      "de4f2faf6da74458bf53b3ba4dd83463",
      "8f4050d427be45568697b93e2cb95561",
      "28f3f5b8e0234c329255538ac96173c9",
      "5b804210d5a04b74ba22df6e7f436a3e",
      "43f969581a374b8d8a73d27df1a50ce6",
      "ca29187326ff41aea93716c7b4070e28",
      "511ce065d92544378d4e4fa98d5ad4f4",
      "82562c3d70b04e998d26a47120408267",
      "9e80c32a9a3e47239119af915408acb9",
      "caf31ed026ea4fbd9b2f7279961f89d1"
     ]
    },
    "id": "front-court",
    "outputId": "0542141d-e65f-4e9e-b33d-47d77a10e446"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ee90cf44c8a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#GPU로 모델 돌릴거라고 말해줌\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \"\"\"\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \"\"\"\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# are found or any other error occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# we need to just return without initializing in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# BertForSequenceClassification(pretrained BERT model with a single linear classification model on top) 로드\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', # 'bert-base-uncased' = lowercase letters만 있는 12 layers BERT 모델 버전\n",
    "    num_labels = 2, #이진 분류이므로 2. 다중 분류에서는 숫자 늘리면 됨.\n",
    "    output_attentions = False, # 모델이 attentions weights를 반환하는지 여부\n",
    "    output_hidden_states = False # 모델이 모든 hidden states를 반환하는지 여부\n",
    ")\n",
    "\n",
    "model.cuda()  #GPU로 모델 돌릴거라고 말해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-playback",
   "metadata": {
    "id": "moderate-valley"
   },
   "source": [
    "### Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-herald",
   "metadata": {
    "id": "social-gambling"
   },
   "source": [
    "모델이 로드되었으니 하이퍼파라미터를 설정.\\\n",
    "Fine-Tuning에는 다음 하이퍼 파라미터 값들이 권장됨\n",
    "* Batch_size: 16, 32\n",
    "* Learning_rate(Adam): 5e-5, 3e-5, 2e-5\n",
    "* Number of epochs: 2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-float",
   "metadata": {
    "id": "prompt-breed"
   },
   "source": [
    "epsilon parameter는 모델 훈련 중 zero-division error를 막기 위한 수.\\\n",
    "eps = 1e-8로 아주 작은 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-cisco",
   "metadata": {
    "id": "built-medication"
   },
   "outputs": [],
   "source": [
    "# AdamW는 huggingface library(<->pytorch)의 클래스다. W는 'Weight Decay Fix'의미하는 듯?\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-present",
   "metadata": {
    "id": "conventional-military"
   },
   "source": [
    "![image.png](attachment:c012adc1-2245-436f-90d2-d823b0062505.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-adaptation",
   "metadata": {
    "id": "marked-packing"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps = # of batchs(전체 데이터셋이 몇개의 batch로 구성되는지) * # of epochs\n",
    "total_steps = len(train_dataloader)* epochs\n",
    "\n",
    "# learning rate scheduler 만들기\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # run_glue.py의 기본값\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-motorcycle",
   "metadata": {
    "id": "enhanced-thriller"
   },
   "source": [
    "### ***훈련 루프 구성***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-script",
   "metadata": {
    "id": "opened-indiana"
   },
   "source": [
    "루프가 한 번씩 돌때마다, 모델이 전체 훈련 데이터를 가지고 학습하고 남겨놓은 검증 데이터를 통해 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-month",
   "metadata": {
    "id": "frequent-speaker"
   },
   "source": [
    "정확도 측정 위한 helper 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-promotion",
   "metadata": {
    "id": "dental-venture"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# labels와 예측치 비교로 정확도를 계산하는 함수 \n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-falls",
   "metadata": {
    "id": "registered-potential"
   },
   "source": [
    "경과한 시간을 측정하기 위한 helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-oxygen",
   "metadata": {
    "id": "pharmaceutical-chair"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    # 근접한 초로 반올림하기\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    # hh:mm:ss 형태로 반환\n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-capacity",
   "metadata": {
    "id": "public-harmony"
   },
   "source": [
    "#### Training 시작!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-lafayette",
   "metadata": {
    "id": "n61hg1dL_mgl"
   },
   "source": [
    "'loss = outputs[0] '코드와 Warnings에 관하여\\(https://github.com/huggingface/transformers/issues/5421)\n",
    "\n",
    "* which means you're only getting the first output of the model, and using that to compute the loss.The first output of the model is the hidden states.\n",
    "* You're ignoring the second value which is the pooler output. \n",
    "* Therefore, the warnings(\"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification\") are normal in your case.\n",
    "- Warnings의 요지는 loss를 계산함에 있어 pooler output은 사용하지 않는다는 것! 그런데 'loss = outputs[0]'라는 코드 자체가 이미 pooler output을 사용하지 않는다는 의도를 가지므로 해당 상황에서는 의미 x\n",
    "+) 'logging.set_verbosity_error()' 코드로 warinings 안뜨게 설정해 놓음\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-machine",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "linear-nicaragua",
    "outputId": "815c3009-407a-4dad-d34d-40e08ecce8be"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 매 에폭마다 평균 loss 저장(나중에 plot으로 시각화 할거임)\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #                 Training\n",
    "    # ========================================\n",
    "    # Training set 전체 한 번 쭈욱 학습\n",
    "    print(\"\")\n",
    "    print('====== Epochs {:} / {:} ======'.format(epoch_i+1, epochs))\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    # 에폭당 훈련 시간이 얼마나 걸리는지 측정하기 위해 훈련 시작 전 시간 측정\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # 에폭당 훈련 들어가기 전 loss값 초기화\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 모델을 training 모드로 설정(아직 훈련 시작한 것은 아님)\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):  # 훈련 데이터의 각 배치당\n",
    "        \n",
    "        # 배치 100개가 학습될 때마다 진행 상황 표시\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # 진행 상황 보고(전체 배치 중 몇 개 배치까지 학습했는지)\n",
    "            print(' Batch  {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "        \n",
    "        # DataLoader에서 training set unpack: unpack하며 to()매서드 통해 tensor들 cpu에 복사\n",
    "        # bathc는 3개의 pytorch tensors를 포함하고 있다:\n",
    "        # [0]: input_ids\n",
    "        # [1]: attention_masks\n",
    "        # [2]: labels\n",
    "        b_input_ids = batch[0].to(device) #.long()\n",
    "        b_input_mask = batch[1].to(device) #.long()\n",
    "        b_labels = batch[2].to(device) #.long()\n",
    "        \n",
    "        # 역전파하기 전 이전에 계산된 gradients들 없애주기(단, RNN할 때는 이전 기울기 남겨두어야)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # 순전파 실행: 해당 훈련 배치에 대한 모델의 훈련 평가\n",
    "        # labels(train_df의 target값)를 제공해 주었기 때문에 모델 실행으로 오류값이 반환됨\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids = None, \n",
    "                        attention_mask = b_input_mask,\n",
    "                        labels = b_labels\n",
    "                       )\n",
    "        # model의 호출 결과 반환값은 튜플의 형태를 띠므로 loss값을 ouputs에서 끌어내 주어야 한다.\n",
    "        loss = outputs[0] \n",
    "        \n",
    "        # 모든 batch들의 training loss 누적 합산하여 마지막에 average loss구할 수 있도록 하기\n",
    "        # loss는 한 개의 값을 가지고 있는 tensor이다. .item()매서드 통해서 tensor에서 python value 꺼내와주기\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # gradient계산 위해 역전파 수행\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradients의 표준을 1로 고정(clip)시켜 'Exploding gradients'문제 예방\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # parameters update하고 계산된 기울기를 이용해 다음 스텝으로 나아감\n",
    "        # 여기서 optimizer는 업데이트 규칙(파라미터가 그들의 기울기, 학습률 등을 근거로 어떻게 수정될 것인가)을 정해줌.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 학슬률 업데이트\n",
    "        scheduler.step()\n",
    "    \n",
    "    # training data 전체에 걸친 평균 loss 계산\n",
    "    avg_train_loss = total_loss/ len(train_dataloader)\n",
    "    \n",
    "    # 학습 곡선 그리기 위해 에폭당 평균 loss값 모두 저장\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\" Average training loss: {:.2f}\".format(avg_train_loss))\n",
    "    # 한 에폭 학습당 걸린 시간 출력\n",
    "    print(\" Training Epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #                 Validation\n",
    "    # ========================================\n",
    "    # 훈련 에폭이 한 번 끝날 때마다 검증 데이터셋을 이용해 모델의 퍼포먼스 측정\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 모델을 평가 모델로 설정-- dropout layers는 evaluation mode일 때 다르게 작동한다.\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 추적\n",
    "    eval_loss, eval_accuracy = 0,0\n",
    "    nb_eval_steps, np_eval_examples = 0,0\n",
    "\n",
    "    # 한 에폭 데이터에 대한 평가\n",
    "    for batch in validation_dataloader:\n",
    "        # GPU에 Batch 추가\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # dataloader의 (바로 위에서 구성된)batch에서 input들 꺼내기\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # 평가 단계므로 모델에게 기울기를 계산하거나 저장하지 않도록 명령.<- 메모리와 검증 속도 높이기 위해\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # 순전파 수행: 예측 로짓값 계산\n",
    "            # 우리가 라벨(정답값= target)을 주지 않았기 때문에 이 모델은 실행 결과 로짓값 반환\n",
    "            # token_types_ids는 \"2-sentence tasks에서의 sentence 1,2와는 다른 segment ids\"와 같다.\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids = None,\n",
    "                            attention_mask = b_input_mask)\n",
    "            \n",
    "        # 모델에서 반환된 로짓값 변수에 담기. 여기서 로짓값은 softmax와 같은 활성화 함수를 적용시키기 전의 산출값이다.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # 로짓값들과 라벨들을 cpu에 옮기기\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 테스트 트윗들을 담은 이 배치에 대해 모델 정확도 계산하기\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # 배치당 정확도 누적 합산\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # 배치의 개수(절차 진행 횟수) 추적\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # 에폭당 검증에 대한 최종 정확도 보고\n",
    "    print(\" Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps)) #배치당 평균 정확도\n",
    "    print(\" Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Complete!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-template",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "VMVITdeuNDAz",
    "outputId": "372fa14d-eb84-4516-94c3-2168d20fdeec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "# 폰트 크기 키우기\n",
    "sns.set(font_scale = 1.5)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# 학습 곡선 그리기\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-dress",
   "metadata": {
    "id": "e6zY6R2oQNKQ"
   },
   "source": [
    "# Test Set Tweets에 대한 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-lodge",
   "metadata": {
    "id": "0oOEuY1ml9Nc"
   },
   "source": [
    "## 데이터 전처리(1)- 처리하기 깔끔한 Corpus 만들기\n",
    "test_set의 모든 행의 tweet에 대한 예측이 수행되어야 하기에 누락값 있다 해서 행 삭제 해서는 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-genetics",
   "metadata": {
    "id": "hWMm5s7jHHQ0"
   },
   "outputs": [],
   "source": [
    "test_df.text = test_df.text.apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-original",
   "metadata": {
    "id": "ojswbK2DQWOv"
   },
   "source": [
    "## 데이터 전처리(2)- 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-finish",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjgVcWIUQKWx",
    "outputId": "b0ce8a8b-3f99-4555-b86e-2cf632cd1ee3"
   },
   "outputs": [],
   "source": [
    "# 모든 문장 토크나이징 하고 id에 따라 분류하기\n",
    "test_input_ids  = []\n",
    "\n",
    "test_token_len = []\n",
    "\n",
    "# 각 트윗 마다...\n",
    "for tweet in test_df.text:\n",
    "    # 진행 상황\n",
    "    if ((len(test_input_ids) % 200) == 0):\n",
    "        print(' Read {:,} tweets.'.format(len(test_input_ids)))\n",
    "    \n",
    "    # encode will\n",
    "    # 1)트윗을 토크나이징하고, \n",
    "    # 2)[CLS]토큰을 시작 부분에, [SEP]토큰을 마지막 부분에 추가하고, \n",
    "    # 3)토큰을 해당 id에 매칭\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        tweet, # Tweet to encode\n",
    "        add_special_tokens = True,  # add_special_tokens: [CLS]와 [SEP]추가'\n",
    "        max_length = 41, # max(test_token_len) = 41이므로. # 참고) public leaderboard 0.82점 나왔을 때는 100으로 설정했음 \n",
    "        #return_tensors = 'pt'  # Return pytorch tensors.\n",
    "    ) \n",
    "    \n",
    "    # encoded된 트윗을 리스트에 넣기\n",
    "    test_input_ids.append(encoded_sent)\n",
    "    \n",
    "    # 각 트윗의 토큰 개수 기록\n",
    "    test_token_len.append(len(encoded_sent))\n",
    "\n",
    "print('DONE.')\n",
    "print('')\n",
    "print('{:>10} tweets'.format(len(test_input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-fishing",
   "metadata": {
    "id": "znZ5ssH6dp6Z"
   },
   "outputs": [],
   "source": [
    "# test_df에는 target없으므로 라벨 생성 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-employer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhPB5QXtgwf2",
    "outputId": "07f76c71-fa1c-4d4b-f38b-0add9d411f25"
   },
   "outputs": [],
   "source": [
    "# 토큰나이징 된 test_df의 tweet들 중 가장 긴 tweet의 단어 개수와 가장 짧은 단어 개수 출력\n",
    "\n",
    "print('전체 test_tweets 중 토큰 최대 개수: {:>,}, 최소 개수: {:>,}, 중간값: {:.0f}'.format(max(test_token_len), min(test_token_len), np.median(test_token_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-flash",
   "metadata": {
    "id": "_p7YeUBRCXjr"
   },
   "source": [
    "#### *** 여기서 train_data padding 할 때와는 달리 value = 0 인자를 삭제해 주니까 학습이 비로소 잘 이루어짐 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-adult",
   "metadata": {
    "id": "3Hw2Q1m4dtdB"
   },
   "outputs": [],
   "source": [
    "# Pad input tokens\n",
    "MAX_LEN = 41 # 참고) public leaderboard 0.82점 나왔을 때는 73으로 돌림\n",
    "test_input_ids = pad_sequences(test_input_ids, maxlen = MAX_LEN, dtype = 'long', truncating = 'post', padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-cherry",
   "metadata": {
    "id": "OgG2W6MtdwJ-"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "test_attention_masks = []\n",
    "# 각 트윗마다...\n",
    "for sent in test_input_ids:\n",
    "    # Attention Mask 만들기\n",
    "    #  - token_id가 0이라면, 패딩이다. 마스크값에 0을 주고,\n",
    "    #  - token_id가 >0이라면, 의미 있는 토큰이므로 마스크값에 1 주기!\n",
    "    seq_mask = [int(token_id>0) for token_id in sent]\n",
    "\n",
    "    test_attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-strengthening",
   "metadata": {
    "id": "xmxso6nsdxns"
   },
   "outputs": [],
   "source": [
    "# torch.tensor로 변환\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-designation",
   "metadata": {
    "id": "Fd-x01x98JdC"
   },
   "source": [
    "#### *** 여기서 Test_sampler을 randomsampler이 아니라 sequentialsampler로 고쳐 주니까 학습이 비로소 잘 이루어짐 ***\n",
    "validation data와 test data는 dataloader에 들어가는 sampler를 구성함에 있어 train data(RandomSampler)와는 달리 SequentialSampler을 사용한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-waste",
   "metadata": {
    "id": "MjHrDLvZd0jN"
   },
   "outputs": [],
   "source": [
    "# DataLoader 만들기\n",
    "# BERT를 fine-tuning할 때 배치 사이즈 16 혹은 32가 권장된다. \n",
    "batch_size = 32\n",
    "\n",
    "# test_set을 위한 Data_loader 만들기\n",
    "test_data= TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-quebec",
   "metadata": {
    "id": "X2Hdt8NDyBAG"
   },
   "source": [
    "# Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-democrat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-02VV9ONyAqL",
    "outputId": "922a0abe-cd52-4936-b09e-9900145da741"
   },
   "outputs": [],
   "source": [
    "# Fine-Tuned 모델로 테스트 셋에 대한 예측 수행\n",
    "print('Predicting labels for {:,} test tweets...'.format(len(test_inputs)))\n",
    "\n",
    "# 모델을 evaluation모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 변수들 추적\n",
    "predictions = []\n",
    "pred_explicit = []\n",
    "\n",
    "# 경과 시간 확인하기 위해 예측 전 시간 측정\n",
    "t0 = time.time()\n",
    "\n",
    "# 예측\n",
    "for (step, batch) in enumerate(test_dataloader):\n",
    "    # GPU에 Batch 추가\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # 100배치당 진행 상황 보고\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        # 경과한 시간 측정\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        # 진행 상황 보고\n",
    "        print(' Batch {:>5,} of  {:>5,}. Elapsed: {:}'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # dataloader의 (바로 위에서 구성된)batch에서 input들 꺼내기\n",
    "    b_input_ids, b_input_mask = batch\n",
    "\n",
    "    # 평가 단계이므로 모델에게 기울기를 계산하거나 저장하지 않도록 명령\n",
    "    with torch.no_grad():\n",
    "        # 순전파 수행: 예측 로짓값 계산\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids = None,\n",
    "                        attention_mask = b_input_mask)\n",
    "        \n",
    "    loss_logits = outputs[0]\n",
    "\n",
    "    # 손실 로짓값을 cpu에 옮기기\n",
    "    logits = loss_logits.detach().cpu().numpy()\n",
    "\n",
    "    # 모델이 내놓은 예측값 저장\n",
    "    predictions.append(logits)\n",
    "\n",
    "    # 예측값(logits)은 [재난 트윗이 아닐 확률을 나타내는 로짓값, 재난 트윗일 확률인 로짓값]으로 산출됨.\n",
    "    # 두 값을 비교하여 더 큰 확률을 지니는 항목를(0 또는 1) 산출하여 pred_explicit 리스트에 추가\n",
    "    for i in range(len(logits)):\n",
    "        if logits[i][0] > logits[i][1]:\n",
    "            pred_explicit.append(0)\n",
    "        else:\n",
    "            pred_explicit.append(1)\n",
    "\n",
    "print('   Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-tokyo",
   "metadata": {
    "id": "L-_yBwRydrwL"
   },
   "outputs": [],
   "source": [
    "# 배치 단위로 주어진 예측값들 concatenate\n",
    "predictions = np.concatenate(predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-cable",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOtlQk_hd8cl",
    "outputId": "754e56c0-a896-4197-fa6d-d954b9c53f0b"
   },
   "outputs": [],
   "source": [
    "# 예측된 결과 조금 살펴보기\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-endorsement",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJL2I-4qL3Qf",
    "outputId": "06270d58-bcaf-4740-e33c-abe64bfc7e9a"
   },
   "outputs": [],
   "source": [
    "# pred_explicit 구성하는 코드가 test_df의 모든 tweet에 대한 예측값을 0 또는 1로 변환했는지 확인\n",
    "len(pred_explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-merchandise",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "gpVh9BTvyWot",
    "outputId": "df9bfd51-19d3-412b-deac-770e54ec9cd6"
   },
   "outputs": [],
   "source": [
    "# pred_explicit 리스트 데이터 프레임으로 만든 뒤 sample_submission에 (예측)값들 넣기\n",
    "sample_submission['target'] = pred_explicit\n",
    "sample_submission[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-pound",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "s-pI1AZQLYqr",
    "outputId": "d22600e0-36ba-488d-bde7-80223107d22e"
   },
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-music",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "mjTLhbgU_2wt",
    "outputId": "aecfa447-04e7-4617-a0f8-bb8868a5cfad"
   },
   "outputs": [],
   "source": [
    "# 예측 정확도 실제 test tweet 보며 직접 가늠해보기\n",
    "test_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-harassment",
   "metadata": {
    "id": "lz0zH17GzBin"
   },
   "outputs": [],
   "source": [
    "# sample_submission csv파일로 저장\n",
    "sample_submission.to_csv('/content/drive/MyDrive/Dacon_Data/[Kaggle]Disaster_Tweets/submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tweeter-Preprocessor + BERT Embedding(0.82255).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2064c5090f21400d836940d4c5c90c56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28f3f5b8e0234c329255538ac96173c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43f969581a374b8d8a73d27df1a50ce6",
       "IPY_MODEL_ca29187326ff41aea93716c7b4070e28"
      ],
      "layout": "IPY_MODEL_5b804210d5a04b74ba22df6e7f436a3e"
     }
    },
    "317f590da93c4773bfc567e1476c9d3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b54731995ac496e9f92577a6fb822ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43f969581a374b8d8a73d27df1a50ce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82562c3d70b04e998d26a47120408267",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_511ce065d92544378d4e4fa98d5ad4f4",
      "value": 440473133
     }
    },
    "471c0056a7f842b8aa5d5d1f8117f9ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48a503528cc24d0e8db6bd6056e80d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b45509a3910044999219a2da6b0fd5d3",
      "placeholder": "​",
      "style": "IPY_MODEL_4c33de7bd446464c9b3e3de8954e3d1c",
      "value": " 466k/466k [00:00&lt;00:00, 5.53MB/s]"
     }
    },
    "4a4e95bae7a34e63b218c2687a99aff8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c33de7bd446464c9b3e3de8954e3d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c7d18eab7b24bf4a237779ead1ec4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "511ce065d92544378d4e4fa98d5ad4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "55dae3e35324482f806dbc48449a0ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_898a5b5a7b4a4d1a8cf317d1317cda2a",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6c797ae4913458e9f99999b12ece9f3",
      "value": 570
     }
    },
    "5b804210d5a04b74ba22df6e7f436a3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6938e752c86c4c9fb22fda671242646e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79f68bacefd94c20ba9c65b22f0c0892": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82562c3d70b04e998d26a47120408267": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "880610c74dc549d88957867b7469ac6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_962245dce77c4cb1ae89f8bd5ccf9830",
       "IPY_MODEL_48a503528cc24d0e8db6bd6056e80d6c"
      ],
      "layout": "IPY_MODEL_3b54731995ac496e9f92577a6fb822ba"
     }
    },
    "898a5b5a7b4a4d1a8cf317d1317cda2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f4050d427be45568697b93e2cb95561": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fcd3ce79f1d45f5a6d31ca8f3515a5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "92fc8899b6e04a4886e66b3c3dca388e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7709c0d0b0f4a2298b5fdd0e0f95d50",
       "IPY_MODEL_ca380b0061e047e1800628a47a547b5d"
      ],
      "layout": "IPY_MODEL_c78eb26897e147f38797dbe2ccd7e4ad"
     }
    },
    "962245dce77c4cb1ae89f8bd5ccf9830": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee13ce48e1964af588039f4dfae9a621",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8fcd3ce79f1d45f5a6d31ca8f3515a5d",
      "value": 466062
     }
    },
    "9e80c32a9a3e47239119af915408acb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2b1452d157449baa090ff17b73be65c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f4050d427be45568697b93e2cb95561",
      "placeholder": "​",
      "style": "IPY_MODEL_de4f2faf6da74458bf53b3ba4dd83463",
      "value": " 570/570 [00:22&lt;00:00, 25.1B/s]"
     }
    },
    "b45509a3910044999219a2da6b0fd5d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba52d4f7697f4b9e9c56b62452efb4d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd4b90bbf5ed425ca531bdf85a784940": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c476ab52d9cb48b8856a820dd368cdb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f29ae599f89f4c07bcaaad154b76069b",
       "IPY_MODEL_d892483b862c45f48c906f2393f1a40f"
      ],
      "layout": "IPY_MODEL_4a4e95bae7a34e63b218c2687a99aff8"
     }
    },
    "c78eb26897e147f38797dbe2ccd7e4ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca29187326ff41aea93716c7b4070e28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caf31ed026ea4fbd9b2f7279961f89d1",
      "placeholder": "​",
      "style": "IPY_MODEL_9e80c32a9a3e47239119af915408acb9",
      "value": " 440M/440M [00:22&lt;00:00, 19.6MB/s]"
     }
    },
    "ca380b0061e047e1800628a47a547b5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2064c5090f21400d836940d4c5c90c56",
      "placeholder": "​",
      "style": "IPY_MODEL_4c7d18eab7b24bf4a237779ead1ec4d4",
      "value": " 232k/232k [00:00&lt;00:00, 611kB/s]"
     }
    },
    "caf31ed026ea4fbd9b2f7279961f89d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d892483b862c45f48c906f2393f1a40f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffbedc1ccaeb43f883189743d0a422c6",
      "placeholder": "​",
      "style": "IPY_MODEL_6938e752c86c4c9fb22fda671242646e",
      "value": " 28.0/28.0 [00:00&lt;00:00, 317B/s]"
     }
    },
    "de4f2faf6da74458bf53b3ba4dd83463": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7709c0d0b0f4a2298b5fdd0e0f95d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471c0056a7f842b8aa5d5d1f8117f9ec",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_317f590da93c4773bfc567e1476c9d3d",
      "value": 231508
     }
    },
    "ebab2506f5334b6ab1e8e09f7a44c12c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55dae3e35324482f806dbc48449a0ac0",
       "IPY_MODEL_a2b1452d157449baa090ff17b73be65c"
      ],
      "layout": "IPY_MODEL_ba52d4f7697f4b9e9c56b62452efb4d1"
     }
    },
    "ee13ce48e1964af588039f4dfae9a621": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f29ae599f89f4c07bcaaad154b76069b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79f68bacefd94c20ba9c65b22f0c0892",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd4b90bbf5ed425ca531bdf85a784940",
      "value": 28
     }
    },
    "f6c797ae4913458e9f99999b12ece9f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ffbedc1ccaeb43f883189743d0a422c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
